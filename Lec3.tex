\documentclass[12pt,a4paper]{article}
\usepackage{amsmath, amssymb}
\usepackage{enumitem}
\usepackage{hyperref}
\setlist{nosep}

\title{Lecture 3 Notes}
\author{}
\date{}

\begin{document}
\maketitle

\section*{Regular Expressions}
Let $\Sigma$ be an alphabet. The regular expressions over $\Sigma$ and the languages they denote are defined as below:

\begin{itemize}
    \item $\phi$ is an RE. $L(\phi) = \phi$
    \item $\epsilon$ is an RE. $L(\epsilon) = \{\epsilon\}$
    \item For each $a \in \Sigma$, $a$ is an RE. $L(a) = \{a\}$
    \item If $r$ and $s$ are REs denoting languages $R$ and $S$, respectively:
    \begin{itemize}
        \item \texttt{(rs)} is an RE, $L(rs) = R \cdot S = \{xy \mid x \in R, y \in S\}$
        \item \texttt{(r+s)} is an RE, $L(r+s) = R \cup S$
        \item \texttt{(r$^*$)} is an RE, $L(r^*) = R^* = \bigcup_{i=0}^{\infty} R^i$ (Kleene closure)
    \end{itemize}
\end{itemize}

\section*{Examples of Regular Expressions}
\begin{itemize}
    \item $L =$ set of all strings of \texttt{0}s and \texttt{1}s:
    \begin{itemize}
        \item $r = \texttt{(0+1)$^*$}$
        \item Example: to generate \texttt{101}, \texttt{(0+1)$^*$ $\Rightarrow^4$ (0+1)(0+1)(0+1)$\epsilon$ $\Rightarrow^4$ 101}
    \end{itemize}

    \item $L =$ set of all strings of \texttt{0}s and \texttt{1}s, with at least two consecutive \texttt{0}s:  
    \texttt{r = (0+1)$^*$00(0+1)$^*$}

    \item $L = \{ w \in \{0,1\}^* \mid w$ has two or three occurrences of \texttt{1}, the first and second of which are not consecutive\}:  
    \texttt{r = 0$^*$10$^*$010$^*$(10$^*$ + $\epsilon$)}

    \item \texttt{r = (1+10)$^*$}  
    $L =$ set of all strings of \texttt{0}s and \texttt{1}s beginning with \texttt{1} and not having two consecutive \texttt{0}s.

    \item \texttt{r = (0+1)$^*$011}  
    $L =$ set of all strings of \texttt{0}s and \texttt{1}s ending in \texttt{011}.

    \item \texttt{r = c$^*$(a+bc$^*)$^*$}  
    $L =$ set of all strings over \{\texttt{a, b, c}\} that do not have the substring \texttt{ac}.

    \item $L = \{w \mid w \in \{a,b\}^*, w$ ends with \texttt{a}\}$:  
    \texttt{r = (a+b)$^*$a}

    \item $L = \{\texttt{if, then, else, while, do, begin, end}\}$:  
    \texttt{r = if + then + else + while + do + begin + end}
\end{itemize}

\section*{Examples of Regular Definitions}
A regular definition is a sequence of equations of the form:  
\texttt{d\_1 = r\_1; d\_2 = r\_2; ...; d\_n = r\_n}  

where each $d_i$ is a distinct name, and each $r_i$ is a regular expression over the symbols $\Sigma \cup \{d_1, d_2, ..., d_{i-1}\}$.

\subsection*{Identifiers and Integers}
\begin{verbatim}
letter = a + b + c + d + e;
digit = 0 + 1 + 2 + 3 + 4;
identifier = letter(letter + digit)^*;
number = digit digit^*;
\end{verbatim}

\subsection*{Unsigned Numbers}
\begin{verbatim}
digit = 0 + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9;
digits = digit digit^*;
optional_fraction = digits + ε;
optional_exponent = (E(+|-|ε)digits) + ε;
unsigned_number = digits optional_fraction optional_exponent;
\end{verbatim}

\section*{Equivalence of REs and FSA}
\begin{itemize}
    \item Let $r$ be an RE. Then there exists an NFA with $\epsilon$-transitions that accepts $L(r)$. (Proof by construction.)
    \item If $L$ is accepted by a DFA, then $L$ is generated by an RE. (Proof is tedious.)
\end{itemize}

\section*{Transition Diagrams}
Transition diagrams are generalized DFAs with the following differences:
\begin{itemize}
    \item Edges may be labelled by a symbol, a set of symbols, or a regular definition.
    \item Some accepting states may be retracting states, indicating that the lexeme does not include the symbol that brought us there.
    \item Each accepting state has an action attached, executed when that state is reached. Typically, it returns a token and attribute value.
\end{itemize}

\subsection*{Transition Diagram for Identifiers and Reserved Words}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
State & Letter & Digit & Other \\
\hline
$q_0$ & $q_1$ & & \\
$q_1$ & $q_1$ & $q_1$ & $q_2$ \\
$q_2$ & & & \\
\hline
\end{tabular}
\end{center}

\section*{Intermediate Code Generation}
\begin{itemize}
    \item Generating machine code directly leads to $m \times n$ compilers for $m$ languages and $n$ machines.
    \item Code optimizer cannot be reused across machines.
    \item Intermediate code solves these by being machine-independent.
\end{itemize}

\section*{Different Types of Intermediate Code}
\begin{itemize}
    \item Quadruples, triples, indirect triples, abstract syntax trees.
    \item Static Single Assignment (SSA): effective optimizations like constant propagation, global value numbering.
    \item Program Dependence Graph (PDG): useful in parallelization and scheduling.
\end{itemize}

\section*{Machine-independent Code Optimization}
\begin{itemize}
    \item Removes inefficiencies (extra copies, redundant evals, etc.).
    \item Improves time, space, or power efficiency.
    \item Techniques: function inlining, loop unrolling, eliminating unused vars.
    \item Relies on data-flow analysis.
\end{itemize}

\subsection*{Examples}
\begin{itemize}
    \item Common sub-expression elimination
    \item Copy propagation
    \item Loop invariant code motion
    \item Partial redundancy elimination
    \item Induction variable elimination
\end{itemize}

\section*{Code Generation}
\begin{itemize}
    \item Converts intermediate code to machine code.
    \item Must consider registers, pipelines, cache, etc.
    \item Generating efficient code is NP-complete; tree pattern matching is common.
    \item Includes register allocation and storage decisions.
\end{itemize}

\section*{Machine-dependent Optimizations}
\begin{itemize}
    \item Peephole optimizations: redundant instruction elimination, using machine idioms (\texttt{INC} vs \texttt{LD+ADD}).
    \item Instruction scheduling to avoid pipeline stalls.
    \item Trace scheduling and software pipelining to increase parallelism.
\end{itemize}

\end{document}

